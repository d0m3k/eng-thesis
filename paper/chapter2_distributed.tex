\chapter{Droga do rozproszenia}
\label{cha:rozproszenie}

Prawo Moore'a (\cite{moore1998cramming}), wspominające o podwajaniu ilości tranzystorów w procesorach, często parafrazowane jako podwajanie ich mocy obliczeniowej, przestaje działać, podczas gdy złożoność problemów i ilość użytkowników szerokopasmowego internetu rośnie. 
Próba skalowania wertykalnego -- polegającego na wzmacnianiu pojedynczych węzłów, przestaje zdawać próbę czasu.

Problem posiada także drugą stronę -- nie wszyscy użytkownicy internetu mogą pozwolić sobie na łącze szerokopasmowe. Szacuje się, że w roku 2017 dostęp do internetu posiada ponad połowa populacji świata; sam wzrost ilości użytkowników sieci Web z Afryki od roku 2000 do 2017 wynosi aż 8503.1\% (\cite{webStats}) – znaczną część tych połączeń stanowią jednak połączenia starych generacji sieci komórkowej, o znacznie ograniczonej przepustowości i ogromnych latencjach. Każdy kolejny węzeł niezbędny do połączenia użytkownika z serwerem końcowym może dokładać cennych milisekund czasu odpowiedzi. 

Autorzy IPFS zauważają w swojej pracy (\cite{ipfsWP}) także inne słabości obecnego internetu – sieć oparta o HTTP jest w prawdzie zdecentralizowana, jako iż treści rozdzielane są pomiędzy miliony węzłów, od gigantycznej sieci Amazon Web Services aż po mikroserwery stojące w domach pasjonatów; brakuje jej jednak faktycznego rozproszenia: ta infrastruktura nie jest gotowa {\em by design} na przyjmowanie gigantycznego ruchu, nie jest w stanie efektywnie przechowywać i udostępniać wielkich zestawów danych; jest również podatna na znikanie danych, jako iż awaria pojedynczego dysku twardego może zatrzymać udostępnianie całej witryny. 

% TODO - Tu trzeba dopisać jakieś przełamanie w kolejną sekcję. Co też o innych systemach rozproszonych?

\section{Zarys historyczny}
\label{sec:teoriaRozproszenia}
W świecie informatyki szybko wyewoluowały \textbf{rozwiązania współbieżne}. Istnienie wielu wątków -- niezależnych od siebie logicznie toków wywołań, operujących na wspólnej pamięci -- i ich przeplot rozwiązywał takie problemy, jak nierówny rozmiar żądań -- działający sekwencyjnie serwer blokowałby się przy poleceniach zajmujących więcej czasu. Dzięki przeplataniu wątków można uniknąć tej sytuacji, a także pozwolić na iluzję symultaniczności -- mimo korzystania z jednego procesora, polecenia wykonywane są {\em pseudorównolegle}, co pozwala między innymi na responsywność interfejsów użytkownika.

Upowszechnienie się komputerów wieloprocesorowych i procesorów wielordzeniowych zaowocowało rozwojem \textbf{obliczeń równoległych}. Istotne jest rozgraniczenie tych dwóch pojęć -- współbieżność jest raczej paradygmatem, sposobem strukturyzacji oprogramowania w sposób, który pozwala na wykonywanie wielu poleceń niezależnie i jednocześnie; równoległość z kolei to możliwość uruchamiania tego typu oprogramowania w tym samym czasie, dzięki mnogiej liczbie procesorów (\cite{concurrencyGo}).

Współbieżność i równoległość rozwiązują problemy obciążenia, ułatwiając operacje na współdzielonej pamięci. Istnieją całe klasy algorytmów naturalnie podatnych zrównoleglaniu: mapowanie, grupowanie, przeszukiwanie czy sortowanie są jednymi z przykładów. Choć w niektórych przypadkach adaptacja algorytmu wymaga jego konkretnej modyfikacji, możliwość rozwiązywania składowych problemu jako niezależnych wątków znacznie przyspiesza wykonanie w środowiskach wieloprocesorowych (\cite{parallelAlgo}).

Skalowanie rozwiązań tego typu może jednak trafić na ścianę kosztów -- niezbędne są duże ilości pamięci RAM i szybkie dyski; cierpi też niezawodność systemu, gdyż jego działanie pozostaje kompletnie uzależnione od utrzymania przy życiu konkretnego komputera. Jeśli komputer musi też propagować dane w sieci, cała komunikacja spoczywa na nim -- i wydajność jego łącza może zawieść w przypadku szczytów obciążenia.

Remedium dla powyższych problemów jest próba rozdzielenia pracy pomiędzy wiele komputerów -- tu pojawia się \textbf{decentralizacja}, podział problemu na podproblemy, którymi zarządzać mogą mniejsze węzły główne, mające dostęp do węzłów roboczych. To rozwiązanie stawia też nowe wyzwania przed projektantami oprogramowania, którzy nie mogą już polegać na współdzielonej pamięci -- dane muszą być przekazywane jakąś sieciową metodą komunikacji.

% TODO - rozwinąć powyższy akapit; wspomnieć choćby o Erlangu, paradygmatach funkcyjnych, unikaniu mutowalności, COW etc.


% TODO -- rozbij trochę to pisanie o obliczeniach rozproszonych -- tutaj tak naprawdę definiujesz coś pomiedzy klastrem a peer-to-peer, więc tego.
Obliczenia decentralizowane uznać można za podklasę \textbf{obliczeń rozproszonych}. Dla potrzeb tej pracy, obliczenia rozproszone zdefiniowane zostaną jako prowadzone przez w pełni autonomiczne węzły, które dzielą między sobą pracę i radzą sobie z pojawianiem się i znikaniem kolejnych elementów sieci; innymi słowy, w warstwie logicznej system równoległy powinien zachowywać się identycznie zarówno przy istnieniu zaledwie jednego węzła sieci, jak i przy milionie -- różnicą powinien być wyłącznie spadek wydajności systemu.
% czy to nie jest klaster, albo peer-to-peer? To jest klaster, TODO -- przepisać na definicję rozproszenia, a z tego zrobić definicję klastra, i chcemy żeby to co robimy było klastrem.

% TODO - zmieść tu gdzieś definicję peer-to-peer.


\begin{figure}[h]
	\centering
	\begin{subfigure}{0.4\textwidth}
		\centering
		\includegraphics[scale=0.6]{parallel.pdf}
		\subcaption{\label{subfigure_a}}
	\end{subfigure}
	\begin{subfigure}{0.5\textwidth}
		\centering
		\includegraphics[scale=0.5]{decentralized.pdf}
		\subcaption{\label{subfigure_b}}
	\end{subfigure}
	\begin{subfigure}{0.6\textwidth}
		\centering
		\includegraphics[scale=0.5]{distributed.pdf}
		\subcaption{\label{subfigure_c}}
	\end{subfigure}
	
	\caption{\label{fig:concurrentVsParalell}Wizualizacja różnicy pomiędzy systemem równoległym \protect\subref{subfigure_a}, jednym z podgrafów systemu zdecentralizowanego \protect\subref{subfigure_b} i rozproszonym \protect\subref{subfigure_c}.}

	%  TODO - lepsza wizualizacja systemu zdecentralizowanego, gdzie faktycznie mamy kilka różnych "master-slavów"
\end{figure}


\section{Narzędzia w rozproszeniu danych}
\label{sec:narzedzia}
Najbardziej istotnym problemem z dziedziny rozproszenia dla systemu dHTTP jest rozproszenie danych -- próba propagowania informacji pomiędzy wiele węzłów sieci, w celach takich jak podniesienie wydajności, obniżenie kosztów, zwiększenie dostępności czy zapewnienie trwałości informacji.

% git


Nie zawsze jednak motywacje stojące za wyciąganiem danych z centralnych serwerów były szczytne. Duży wpływ na rozwój technik stosowanych obecnie -- w tym wykorzystywanych przez dHTTP -- mają rozwiązania rozpowszechnione głównie przez piractwo komputerowe. Rozwiązania peer-to-peer -- polegające na współpracy równorzędnych węzłów -- zostały spopularyzowane dzięki aplikacji Napster, która w roku 2001 zgromadziła około 80 milionów użytkowników. Zaprojektowana jako system współdzielenia plików, wyspecjalizowała się w łatwym udostępnianiu plików MP3, z reguły nieleganie. Napster wzburzył wiele kontrowersji -- w systemie pojawiały się niewydane jeszcze utwory znanych artystów, prowadząc do milionowych strat i procesu, który pogrążył działanie systemu.
Problemem Napstera była architektura oparta o centralny serwer indeksujący -- każdy podpięty węzeł informował o posiadanych przez siebie plikach, a punkt centralny był niezbędny do przeszukiwania bazy plików i przekazywania poleceń pobrania innym węzłom. To rozwiązanie było niebezpieczne, i pozwoliło obciążyć twórców programu odpowiedzialnością za szerzone w nim treści.

Błędy Napstera zostały zauważone przy kolejnych projektach tego typu. Gnutella, chcąc uniknąć istnienia {\em single point of failure}, rozgłaszała polecenia do wszystkich maszyn w sieci, co owocowało drastycznym spadkiem wydajności.

Chcąc pogodzić kwestie bezpieczeństwa i wydajności systemu, rozpoczęte zostały intensywne prace nad 

\section{Podstawa projektu}
\label{sec:podstawaProjektu}
